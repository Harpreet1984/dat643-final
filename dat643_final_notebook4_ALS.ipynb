{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>DATA643: Recommender System </center>\n",
    "## <center> Final Project </center>\n",
    "### <i> <center> Harpreet Shoker, Rose Koh, Summer 2018 </center> </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook4_ALS\n",
    "\n",
    "In this notebook, we perform matrix factorization using Alternating Least Squares on implicit feedback data.\n",
    "\n",
    "#### ALS with Spark ML library \n",
    "\n",
    "Spark MLlib library for Machine Learning provides a Collaborative Filtering implementation by using Alternating Least Squares. The implementation in MLlib has these parameters:\n",
    "\n",
    "* numBlocks is the number of blocks used to parallelize computation (set to -1 to auto-configure).\n",
    "* rank is the number of latent factors in the model.\n",
    "* iterations is the number of iterations to run.\n",
    "* lambda specifies the regularization parameter in ALS.\n",
    "* implicitPrefs specifies whether to use the explicit feedback ALS variant or one adapted for implicit feedback data.\n",
    "* alpha is a parameter applicable to the implicit feedback variant of ALS that governs the baseline confidence in preference observations.\n",
    "\n",
    "See documentation at https://spark.apache.org/docs/2.2.0/ml-collaborative-filtering.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "datasets_path = os.path.join(os.getcwd(), 'data')\n",
    "dt_path = os.path.join(datasets_path, 'instacart_2017_05_01.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aisles.csv\n",
      "departments.csv\n",
      "order_products__prior.csv\n",
      "order_products__train.csv\n",
      "orders.csv\n",
      "products.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"./data/instacart_2017_05_01\"]).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Order and User dataset\n",
    "order_products_prior = pd.read_csv('./data/instacart_2017_05_01/order_products__prior.csv')\n",
    "order_products_train = pd.read_csv('./data/instacart_2017_05_01/order_products__train.csv')\n",
    "orders = pd.read_csv('./data/instacart_2017_05_01/orders.csv')\n",
    "# Products dataset\n",
    "products = pd.read_csv('./data/instacart_2017_05_01/products.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data(path, orders, order_products_train):\n",
    "    \"\"\"\n",
    "    Make test data and save it in the given path as .csv\n",
    "    \"\"\"\n",
    "    # read `orders` and filter eval_set == train\n",
    "    orders_train = orders.loc[(orders.eval_set == \"train\")].reset_index()\n",
    "    orders_userid = orders_train[[\"order_id\", \"user_id\"]]\n",
    "    \n",
    "    # `orders_userid` and `order_products_train` lengths should match\n",
    "    assert len(orders_userid[\"order_id\"].unique()) == len(order_products_train[\"order_id\"].unique())\n",
    "\n",
    "    # Convert `order_products`_train as same format\n",
    "    orders_productid = order_products_train[[\"order_id\", \"product_id\"]]\n",
    "    orders_productid = orders_productid.groupby(\"order_id\")[\"product_id\"].apply(list).reset_index().rename(columns={\"product_id\": \"products\"})\n",
    "\n",
    "    # `orders_products_train` and `orders_productid` size should match\n",
    "    assert orders_productid.size == orders_userid.size\n",
    "\n",
    "    # merge `orders_userid` and `orders_productid` on order_id\n",
    "    user_products_test = pd.merge(orders_userid, orders_productid, on=\"order_id\")\n",
    "    user_products_test = user_products_test[[\"user_id\", \"products\"]]\n",
    "\n",
    "    # save as .csv\n",
    "    user_products_test.to_csv(path, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 181 ms, sys: 41.3 ms, total: 222 ms\n",
      "Wall time: 222 ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "%%time\n",
    "# Generate test data if it doesn't exist\n",
    "if_test_data_exists = False\n",
    "test_data_path = \"./data/user_products__test.csv\"\n",
    "\n",
    "if if_test_data_exists or not Path(test_data_path).is_file():\n",
    "    test_data(test_data_path, orders, order_products_train)\n",
    "\n",
    "user_products_test_df = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131209, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>products</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[196, 25133, 38928, 26405, 39657, 10258, 13032...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[22963, 7963, 16589, 32792, 41787, 22825, 1364...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>[15349, 19057, 16185, 21413, 20843, 20114, 482...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>[12053, 47272, 37999, 13198, 43967, 40852, 176...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>[15937, 5539, 10960, 23165, 22247, 4853, 27104...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                           products\n",
       "0        1  [196, 25133, 38928, 26405, 39657, 10258, 13032...\n",
       "1        2  [22963, 7963, 16589, 32792, 41787, 22825, 1364...\n",
       "2        5  [15349, 19057, 16185, 21413, 20843, 20114, 482...\n",
       "3        7  [12053, 47272, 37999, 13198, 43967, 40852, 176...\n",
       "4        8  [15937, 5539, 10960, 23165, 22247, 4853, 27104..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(user_products_test_df.shape)\n",
    "user_products_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_item_prior_df(path, orders, order_products_prior):\n",
    "    \"\"\"\n",
    "    Make prior user-product dataframe and save it as .csv\n",
    "    \"\"\"   \n",
    "    \n",
    "    # read `orders` and filter eval_set == prior\n",
    "    orders_user_prior = orders.loc[orders.eval_set == \"prior\"]\n",
    "    orders_user_prior = orders_user_prior[[\"order_id\", \"user_id\"]]\n",
    "    \n",
    "    # merge `orders_user_prior` and `order_products_prior` on order_id\n",
    "    merged = pd.merge(orders_user_prior, order_products_prior[[\"order_id\", \"product_id\"]], on=\"order_id\")\n",
    "    user_item_prior = merged[[\"user_id\", \"product_id\"]]\n",
    "    user_item_prior = user_item_prior.groupby([\"user_id\", \"product_id\"]).size().reset_index().rename(columns={0:\"quantity\"})\n",
    "    \n",
    "    # save as .csv\n",
    "    user_item_prior.to_csv(path, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 18s, sys: 9.8 s, total: 1min 28s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Generate users prior purchases data if it doesn't exist\n",
    "if_user_prod_df_exists = True\n",
    "matrix_df_path = \"./data/user_products__prior.csv\"\n",
    "\n",
    "if if_user_prod_df_exists or not Path(matrix_df_path).is_file():\n",
    "    user_item_prior_df(matrix_df_path, orders, order_products_prior)\n",
    "\n",
    "user_item_prior = pd.read_csv(matrix_df_path)\n",
    "user_item_prior[\"user_id\"] = user_item_prior[\"user_id\"].astype(\"category\")\n",
    "user_item_prior[\"product_id\"] = user_item_prior[\"product_id\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13307953, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10258</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>12427</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13032</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id product_id  quantity\n",
       "0       1        196        10\n",
       "1       1      10258         9\n",
       "2       1      10326         1\n",
       "3       1      12427        10\n",
       "4       1      13032         3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(user_item_prior.shape)\n",
    "user_item_prior.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Item Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse as sparse\n",
    "import numpy as np\n",
    "\n",
    "def build_user_item_matrix(path, user_item_prior):\n",
    "    \"\"\"\n",
    "    make user-item matrix that displays order history of users, save it as .csv\n",
    "    rows = products\n",
    "    columns = users\n",
    "    \"\"\"\n",
    "    user_item_matrix = sparse.coo_matrix((user_item_prior[\"quantity\"],\n",
    "                                          (user_item_prior[\"product_id\"].cat.codes.copy(),\n",
    "                                           user_item_prior[\"user_id\"].cat.codes.copy())))    \n",
    "    sparse.save_npz(path, user_item_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataframe of users, products and quantity bought using prior datasets\n",
    "if_user_item_matrix_exists = False\n",
    "matrix_path = \"./data/user_item_matrix.npz\"\n",
    "\n",
    "if if_user_item_matrix_exists or not Path(matrix_path).is_file():\n",
    "    build_user_item_matrix(matrix_path, user_item_prior)  \n",
    "\n",
    "user_item_matrix=sparse.load_npz(matrix_path).tocsr().astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<49677x206209 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 13307953 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_matrix.shape\n",
    "user_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sparsity of user_item_matrix is 99.8701%\n"
     ]
    }
   ],
   "source": [
    "sparsity = (1 - (user_item_matrix.size / (user_item_matrix.shape[0] * user_item_matrix.shape[1])))\n",
    "print(('The sparsity of user_item_matrix is ') +  str(round(sparsity,6)*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Alternate Least Squares - Implicit Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import implicit\n",
    "\n",
    "def confidence_matrix(user_item_matrix, alpha):\n",
    "    \"\"\"\n",
    "    Given a utility matrix,\n",
    "    Returns the given matrix converted to a confidence matrix\n",
    "    For more details, look at http://yifanhu.net/PUB/cf.pdf\n",
    "    \"\"\"\n",
    "    return (user_item_matrix * alpha).astype(\"double\")\n",
    "    \n",
    "from implicit.als import AlternatingLeastSquares\n",
    "\n",
    "def build_imf(user_item_matrix, **kwargs):\n",
    "    \"\"\"\n",
    "    Given the utility matrix and model parameters,\n",
    "    Builds models and writes it to disk at \n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    # Build model\n",
    "    print(\"Building IMF model with alpha: {} ...\".format(kwargs[\"alpha\"]))\n",
    "    model = AlternatingLeastSquares()\n",
    "    model.approximate_similar_items = False\n",
    "    \n",
    "    model.fit(confidence_matrix(user_item_matrix, kwargs[\"alpha\"]))\n",
    "\n",
    "    # Save model to disk\n",
    "    with open(kwargs[\"path\"], \"wb+\") as f:\n",
    "        pickle.dump(model, f, pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    print(\"Completed in {:.2f}s\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify model params and build it\n",
    "## Alpha's in the range [10, 50] with a step size of 5 were tried. alpha = 15 was found to have the best overall \n",
    "## recall value. \n",
    "model_params = {\"alpha\": 15} \n",
    "model_params[\"path\"] = \"./models/implicit_matrix_factorization/{}.imf\".format(model_params[\"alpha\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "REBUILD_MODEL = False\n",
    "if REBUILD_MODEL or not Path(model_params[\"path\"]).exists():\n",
    "    build_imf(user_item_matrix, **model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(model_params[\"path\"], \"rb\") as f:\n",
    "    imf_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALS with Spark ML library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \"--conf spark.driver.memory=2g  pyspark-shell\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#Start Spark session with local master and 2 cores\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"ALS\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read in user_item_prior from \"./data/user_products__prior.csv\"\n",
    "data = spark.read.csv(matrix_df_path, inferSchema=True, header=True)\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-----------------+\n",
      "|summary|           user_id|        product_id|         quantity|\n",
      "+-------+------------------+------------------+-----------------+\n",
      "|  count|          13307953|          13307953|         13307953|\n",
      "|   mean|         6653976.0|102998.69201506798|25513.50658301844|\n",
      "| stddev|3841675.2677940084| 59436.76555726704|14224.29023480084|\n",
      "|    min|                 0|                 1|                1|\n",
      "|    max|          13307952|            206209|            49688|\n",
      "+-------+------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.6 ms, sys: 17 ms, total: 49.6 ms\n",
      "Wall time: 3min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Build the recommendation model using ALS on the training data\n",
    "als = ALS(maxIter=5, regParam=0.1, implicitPrefs=True, nonnegative=True,\\\n",
    "          coldStartStrategy=\"drop\",\\\n",
    "          userCol='user_id', itemCol='product_id', ratingCol='quantity')\n",
    "\n",
    "als.setSeed(23)\n",
    "model = als.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorized user matrix with rank = 10\n",
      "+---+--------------------+\n",
      "| id|            features|\n",
      "+---+--------------------+\n",
      "|  0|[0.0, 0.0, 0.0, 0...|\n",
      "| 10|[0.0, 0.0, 0.0, 0...|\n",
      "| 20|[0.0, 0.0, 0.0, 0...|\n",
      "| 30|[0.0, 0.0, 0.0, 0...|\n",
      "| 40|[0.0, 0.0, 0.0, 0...|\n",
      "+---+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "----------------------------------------\n",
      "Factorized item matrix with rank = 10\n",
      "+---+--------------------+\n",
      "| id|            features|\n",
      "+---+--------------------+\n",
      "| 10|[0.0, 0.0, 0.0, 0...|\n",
      "| 20|[0.0, 0.0, 0.0, 0...|\n",
      "| 30|[0.0, 0.0, 0.0, 0...|\n",
      "| 40|[0.0, 0.0, 0.0, 0...|\n",
      "| 50|[0.0, 0.0, 0.0, 0...|\n",
      "+---+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Factorized user matrix with rank = %d' % model.rank)\n",
    "model.userFactors.show(5)\n",
    "\n",
    "print('-'*40)\n",
    "\n",
    "print('Factorized item matrix with rank = %d' % model.rank)\n",
    "model.itemFactors.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
